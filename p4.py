# -*- coding: utf-8 -*-
"""p4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YVtYFI1kwyCRDkr_rsX5nRHbo60DiZiQ
"""
from __future__ import print_function, division
# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

"""# SISTEMA DE DIAGNÓSTICO AUTOMÁTICO DE LESIONES CUTÁNEAS A PARTIR DE IMAGEN DERMATOSCÓPICA


En esta práctica vamos a programar un sistema baśico de diagnóstico de lesiones cutáneas a partir de imagen dermatoscópica.

## Parte 0: El problema

Antes de comenzar la práctica, describiremos brevemente la base de datos que utilizaremos en la práctica y el problema que queremos resolver:

Para la evaluación de la primera parte de la asignatura, vamos a desarrollar una CNN que permita el diagnóstico automático de enfermedades cutáneas a partir de imagen dermatoscópica. La Dermatoscopia es una técnica no invasiva que permite la evaluación de los colores y microestructuras de la epidermis, la junta dermoepidermal y la dermis papilar que no son visibles a simple vista. Estas estructuras están específicamente correladas con propiedades histológicas de las lesiones. La identificación de patrones visuales específicos relacionados con la distribución de los colores o las estructuras dermatoscópicas puede ayudar a los dermatólogos a decidir la malignidad de una lesión pigmentada. El uso de esta técnica proporciona una gran ayuda a los expertos para fundamentar su diagnóstico. No obstante, la complejidad de su análisis, limita su aplicación a médicos o dermatólogos expertos.

En nuestro escenario, vamos a clasificar lesiones en 3 clases:
- Melanoma maligno: Melanoma, también conocido como melanoma maligno, es el tipo de cáncer más habitual, y surge de las células pigmentadas conocidas como melanocitos. Los melanomas ocurren típicamente en la piel y raramente en otras partes como la boca, los intestinos o el ojo.

- Queratosis seborreica: es un tumor de la piel no canceroso (benigno) que se origina en las células de la capa exterior de la piel (queranocitos), por lo que se trata de una lesión no melanocítica. 

- Nevus benigno: un tumor de la piel benigno, originado por los melanocitos (es melanocítico)

En la Figura 1 proporcionamos un ejemplo de las 3 lesiones:

![Image of ISIC](http://www.tsc.uc3m.es/~igonzalez/images/ISIC.jpg)

El dataset se ha obtenido del archivo de la 'Internatial Skin Imaging Collaboration' (ISIC). Contiene 2750 imágenes divididas en 3 conjuntos:
- Conjunto de entrenamiento: 2000 imágenes
- Conjunto de validación: 150 imágenes
- Conjunto de test: 600 imágenes

Para cada caso clínico a diagnosticar se dispone de dos imágenes:
- La imagen dermatoscópica de la lesión (en la carpeta ‘images’).
- Una máscara binaria con la segmentación entre lesión (lunar) y piel (en la carpeta 'masks')

Hay un fichero csv por cada dataset (entrenamiento, validación y test) en el que cada caso clínico ocupa una línea con dos campos separados por comas:
- el id numérico de la lesión: que permite construir los paths a la imagen y máscara.
- la etiqueta de lesión: disponibles únicamente para entrenamiento y validación, siendo un número entero entre 0 y 2: 0: nevus benigno, 1: melanoma maligno, 2: queratosis seborreica. En el caso del conjunto de test, las etiquetas no están disponibles (aparecen a -1).

Los estudiantes podrán utilizar los conjuntos de entrenamiento y validación para construir sus soluciones y finalmente proporcionan los scores asociados al conjunto de test. En esta práctica se ayudará a construir un sistema básico de referencia. Para ello tenemos que preparar dos procedimientos fundamentales:

- 1) Procesar una base de datos propia con pytorch
- 2) Hacer fine-tuning de una red habitual para nuestro problema de diagnóstico

## Parte 1: Manejar una base de datos propia con pytorch
Vamos a estudiar cómo podemos cargar y preprocesar una base de datos propia en pytorch. Para ello vamos a usar el paquete ``scikit-image``, que nos permitirá leer las imágenes, y el paquete ``panda`` para leer ficheros csv.

"""


import os
import torch
import pandas as pd
from skimage import io, transform
from sklearn import metrics
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils, models
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.optim import lr_scheduler
import time
import copy
import numpy.random
import pdb

# Ignore warnings
import warnings
warnings.filterwarnings("ignore")

plt.ion()   # interactive mode
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

"""Lo primero que vamos a hacer es descargar y descomprimir la base de datos a un directorio local de trabajo:



"""

#SOLO PARA EJECUTAR EN GOOGLE COLAB. Haga esto una única vez sobre la máquina en la que quiera ejecutar su código y luego puede comentar el código
from shutil import copyfile
from google.colab import drive
import os, sys
drive.mount('/content/drive')
copyfile('/content/drive/My Drive/Colab Notebooks/db1.zip', './db1.zip') #Copiamos el fichero a nuestra carpeta de trabajo
copyfile('/content/drive/My Drive/Colab Notebooks/db2.zip', './db2.zip')

#NOTA: Haga esto una única vez sobre la máquina en la que quiera ejecutar su código y luego puede comentar el código
import zipfile
zipPath='/content/drive/My Drive/Colab Notebooks/db1.zip' #ponemos el path al fichero zip
dataFolder='./data' # We extract files to the current folder
with zipfile.ZipFile(zipPath, 'r') as zip_ref:
    zip_ref.extractall(dataFolder)
    
zipPath='/content/drive/My Drive/Colab Notebooks/db2.zip' #ponemos el path al fichero zip
dataFolder='./data' # We extract files to the current folder
with zipfile.ZipFile(zipPath, 'r') as zip_ref:
   zip_ref.extractall(dataFolder)

"""Ahora vamos a leer el fichero de indexado, que nos proporciona las etiquetas y vamos a mostrar los datos de la imagen 65. La estructura del fichero es una fila por imagen de la base de datos, y dos campos:
- ID de la imagen (una secuencia de 4 dígitos, añadiendo 0s a la izquierda si es necesario)
- Etiqueta: 0 nevus benigno, 1 melanoma, 2 queratosis seborreica

"""

db = pd.read_csv('data/dermoscopyDBtrain.csv',header=0,dtype={'id': str, 'label': int})

#We show inform
n = 65
img_id = db.id[65] 
label = db.label[65]


print('Image ID: {}'.format(img_id))
print('Label: {}'.format(label))

"""Ahora vamos a hacer una función muy sencilla que nos permita mostrar una imagen.



"""

def imshow(image, title_str):
    if len(image.shape)>2:
        plt.imshow(image)
    else:
        plt.imshow(image,cmap=plt.cm.gray)
    plt.title(title_str)        

plt.figure()
imshow(io.imread(os.path.join('data/images/', img_id + '.jpg' )),'Imagen %d'%n)
plt.figure()
imshow(io.imread(os.path.join('data/masks/', img_id + '.png')),'Máscara %d'%n)

plt.show()

"""### Clase Dataset

La clase ``torch.utils.data.Dataset`` es una clase abstracta que representa un dataset.

Para crear nuestro propio dataset en pytorch debemos heredar de dicha clase y sobreescribir los siguientes métodos:

-  ``__len__`` de modo que ``len(dataset)`` nos devuelva el tamaño del dataset.
-  ``__getitem__`` para soportar el indexado ``dataset[i]`` al referirnos a la muestra $i$ 

Vamos a crear los datasets de train y test de nuestro problema de diagnóstico. Vamos a leer el csv en el método de inicialización ``__init__`` pero dejaremos la lectura explícita de las imágenes para el método
``__getitem__``. Esta aproximación es más eficiente en memoria porque todas las imágenes no se cargan en memoria al principio, sino que se van leyendo individualmente cuando es necesario.

Nuestro dataset va a ser un diccionario ``{'image': image, 'mask': mask, 'label': label}``. También podrá tomar un argumento opcional  ``transform`` para que podamos añadir pre-procesado y técnicas de data augmentation.



"""

class DermoscopyDataset(Dataset):
    """Dermoscopy dataset."""

    def __init__(self, csv_file, root_dir,transform=None, maxSize=0):
        """
        Args:
            csv_file (string): Path al fichero csv con las anotaciones.
            root_dir (string): Directorio raíz donde encontraremos las carpetas 'images' y 'masks' .
            transform (callable, optional): Transformaciones opcionales a realizar sobre las imágenes.
            maxSize (un número): número máximo de imágenes a incluir en la base de datos, útil para
                                ejecutar más rápido sobre un subconjunto de los datos. Si maxSize=0
                                se usan todos los datos.
        """
        self.dataset = pd.read_csv(csv_file,header=0,dtype={'id': str, 'label': int})
        
        if maxSize>0:
            newDatasetSize=maxSize #maxSize muestras
            idx=np.random.RandomState(seed=42).permutation(range(len(self.dataset)))
            reduced_dataset=self.dataset.iloc[idx[0:newDatasetSize]]
            self.dataset=reduced_dataset.reset_index(drop=True)

        self.root_dir = root_dir
        self.img_dir = os.path.join(root_dir,'images') 
        self.mask_dir = os.path.join(root_dir,'masks')
        self.transform = transform
        self.classes = ['nevus', 'melanoma', 'keratosis']
    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        #Leemos la imagen
        img_name = os.path.join(self.img_dir,self.dataset.id[idx] + '.jpg')
        image = io.imread(img_name)
        #Leemos la máscara
        mask_name = os.path.join(self.mask_dir,self.dataset.id[idx] + '.png')
        mask = io.imread(mask_name)
        
        sample = {'image': image, 'mask': mask, 'label':  self.dataset.label[idx].astype(dtype=np.long)}
        if self.transform:
            sample = self.transform(sample)
        return sample

"""Vamos a instanciar la clase a iterar sobre algunas muestras para ver lo que generamos.


"""

train_dataset = DermoscopyDataset(csv_file='data/dermoscopyDBtrain.csv',
                                    root_dir='data')


fig = plt.figure()

for i in range(len(train_dataset)):
    sample = train_dataset[i]
    print(i, sample['image'].shape, sample['label'])

    ax = plt.subplot(1, 4, i + 1)
    plt.tight_layout()
    ax.set_title('Sample #{}'.format(i))
    ax.axis('off')
    plt.imshow(sample['image'])

    if i == 3:
        plt.show()
        break

"""### Transformaciones
----------


"""

class CropByMask(object):
    """Recortamos la imagen usando la máscara de la lesión.

    Args:
        border (tupla o int): El borde de recorte alrededor de la máscara. Es sabido que el análisis del borde
        de la lesión con la piel circudante es importante para los dermatólogos, por lo que puede ser interesante
        dejar una guarda.
        Si es una tupla, entonces es (bordery,borderx)
    """

    def __init__(self, border):
        assert isinstance(border, (int, tuple))
        if isinstance(border, int):
            self.border = (border,border)
        else:
            self.border = border
            
    def __call__(self, sample):
        image, mask, label = sample['image'], sample['mask'],sample['label']
        h, w = image.shape[:2]
        #Calculamos los índices del bounding box para hacer el cropping
        sidx=np.nonzero(mask)
        minx=np.maximum(sidx[1].min()-self.border[1],0)
        maxx=np.minimum(sidx[1].max()+1+self.border[1],w)
        miny=np.maximum(sidx[0].min()-self.border[0],0)
        maxy=np.minimum(sidx[0].max()+1+self.border[1],h)
        #Recortamos la imagen
        image=image[miny:maxy,minx:maxx,...]
        mask=mask[miny:maxy,minx:maxx]

        return {'image': image, 'mask': mask, 'label' : label}
    
class Rescale(object):
    """Re-escalamos la imagen a un tamaño determinado.

    Args:
        output_size (tupla o int): El tamaño deseado. Si es una tupla, output es el output_size. 
        Si es un int, la dimensión más pequeña será el output_size
            y mantendremos la relación de aspecto original.
    """

    def __init__(self, output_size):
        assert isinstance(output_size, (int, tuple))
        self.output_size = output_size

    def __call__(self, sample):
        image, mask, label = sample['image'], sample['mask'],sample['label']

        h, w = image.shape[:2]
        if isinstance(self.output_size, int):
            if h > w:
                new_h, new_w = self.output_size * h / w, self.output_size
            else:
                new_h, new_w = self.output_size, self.output_size * w / h
        else:
            new_h, new_w = self.output_size

        new_h, new_w = int(new_h), int(new_w)

        img = transform.resize(image, (new_h, new_w))
        msk = transform.resize(mask, (new_h, new_w))

        return {'image': img, 'mask': msk, 'label' : label}


class RandomCrop(object):
    """Recortamos aleatoriamente la imagen.

    Args:
        output_size (tupla o int): Tamaño del recorte. Si int, recorte cuadrado

    """

    def __init__(self, output_size):
        assert isinstance(output_size, (int, tuple))
        if isinstance(output_size, int):
            self.output_size = (output_size, output_size)
        else:
            assert len(output_size) == 2
            self.output_size = output_size

    def __call__(self, sample):
        image, mask, label = sample['image'], sample['mask'],sample['label']

        h, w = image.shape[:2]
        new_h, new_w = self.output_size

        if h>new_h:
            top = np.random.randint(0, h - new_h)
        else:
            top=0
            
        if w>new_w: 
            left = np.random.randint(0, w - new_w)
        else:
            left = 0
            
        image = image[top: top + new_h,
                     left: left + new_w]

        mask = mask[top: top + new_h,
                      left: left + new_w]


        return {'image': image, 'mask': mask, 'label': label}

class CenterCrop(object):
    """Recortamos la imagen centrándonos.

    Args:
        output_size (tupla o int): Tamaño del recorte. Si int, recorte cuadrado

    """

    def __init__(self, output_size):
        assert isinstance(output_size, (int, tuple))
        if isinstance(output_size, int):
            self.output_size = (output_size, output_size)
        else:
            assert len(output_size) == 2
            self.output_size = output_size

    def __call__(self, sample):
        image, mask, label = sample['image'], sample['mask'],sample['label']
        h, w = image.shape[:2]
        new_h, new_w = self.output_size
        rem_h = h - new_h
        rem_w = w - new_w
        
        if h>new_h:
            top = int(rem_h/2)
        else:
            top=0
            
        if w>new_w: 
            left = int(rem_w/2)
        else:
            left = 0
            
        image = image[top: top + new_h,
                     left: left + new_w]

        mask = mask[top: top + new_h,
                      left: left + new_w]


        return {'image': image, 'mask': mask, 'label': label}

class ToTensor(object):
    """Convertimos ndarrays de la muestra en tensores."""

    def __call__(self, sample):
        image, mask, label = sample['image'], sample['mask'],sample['label']

        # Cambiamos los ejes
        # numpy image: H x W x C
        # torch image: C X H X W
        image = image.transpose((2, 0, 1))
        image = torch.from_numpy(image)
        # A la máscara le añadimos una dim fake al principio
        mask = torch.from_numpy(mask)
        mask = mask.unsqueeze(0)
        label=torch.tensor(label,dtype=torch.long)
        
        return {'image':image,
                'mask':mask,
                'label':label}
    
class Normalize(object):
    """Normalizamos los datos restando la media y dividiendo por las desviaciones típicas.

    Args:
        mean_vec: El vector con las medias. 
        std_vec: el vector con las desviaciones típicas.
    """

    def __init__(self, mean,std):
      
        assert len(mean)==len(std),'Length of mean and std vectors is not the same'
        self.mean = np.array(mean)
        self.std = np.array(std)

    def __call__(self, sample):
        image, mask, label = sample['image'], sample['mask'],sample['label']
        c, h, w = image.shape
        assert c==len(self.mean), 'Length of mean and image is not the same' 
        dtype = image.dtype
        mean = torch.as_tensor(self.mean, dtype=dtype, device=image.device)
        std = torch.as_tensor(self.std, dtype=dtype, device=image.device)
        image.sub_(mean[:, None, None]).div_(std[:, None, None])
    
        
        return {'image': image, 'mask': mask, 'label' : label}

"""### Transformaciones compuestas

Ahora vamos a aplicar las diferentes transformaciones a nuestras imágenes.
Vamos a reescalar las imágenes para que su dimensión menor sea de 256 y luego haremos crops aleatorios de tamaño 224. Después, haremos una composición de transformaciones ``CropByMask``, ``Rescale`` y ``RandomCrop`` utilizando ``torchvision.transforms.Compose``, que es una simple clase invocable.



"""

cmask = CropByMask(15)
scale = Rescale(256)
crop = RandomCrop(224)
composed = transforms.Compose([CropByMask(15), Rescale(256),
                               RandomCrop(224)])

# Apply each of the above transforms on sample.
fig = plt.figure()
sample = train_dataset[65]
ax = plt.subplot(2,3, 1)
plt.tight_layout()
ax.set_title('original')
plt.imshow(sample['image'])
    
for i, tsfrm in enumerate([cmask, scale, crop, composed]):
    transformed_sample = tsfrm(sample)

    ax = plt.subplot(2, 3, i + 2)
    plt.tight_layout()
    ax.set_title(type(tsfrm).__name__)
    plt.imshow(transformed_sample['image'])

plt.show()

"""Iterando el dataset
-----------------------------

Ahora vamos a poner todo en común para crear los datasets de train y test con las transformaciones correspondientes.
En resumen, cada vez que muestreemos alguna imagen del dataset (de train):
- Leeremos la imagen y la máscara 
- Aplicaremos las transformaciones y recortaremos la imagen con el bounding box de la máscara
- Como el cropping final es aleatorio, estaremos aplicando data augmentation durante el muestreo

Podemos iterar de manera sencilla sobre el dataset con un bucle ``for i in range``.



"""

#Datos de train
train_dataset = DermoscopyDataset(csv_file='data/dermoscopyDBtrain.csv',
                                    root_dir='data',
                                    transform=transforms.Compose([
                                    CropByMask(15),
                                    Rescale(224),
                                    RandomCrop(224),
                                    ToTensor(),
                                    Normalize(mean=[0.485, 0.456, 0.406],
                                    std=[0.229, 0.224, 0.225])
                                    ]))
#Datos de test
val_dataset = DermoscopyDataset(csv_file='data/dermoscopyDBval.csv',
                                    root_dir='data',
                                    transform=transforms.Compose([
                                    CropByMask(15),
                                    Rescale(224),
                                    CenterCrop(224),
                                    ToTensor(),
                                    Normalize(mean=[0.485, 0.456, 0.406],
                                    std=[0.229, 0.224, 0.225])
                                    ]))

#Datos de test
test_dataset = DermoscopyDataset(csv_file='data/dermoscopyDBtest.csv',
                                    root_dir='data',
                                    transform=transforms.Compose([
                                    CropByMask(15),
                                    Rescale(224),
                                    CenterCrop(224),
                                    ToTensor(),
                                    Normalize(mean=[0.485, 0.456, 0.406],
                                    std=[0.229, 0.224, 0.225])
                                    ]))

for i in range(len(train_dataset)):
    sample = train_dataset[i]

    print(i, sample['image'].size(), sample['label'])

    if i == 3:
        break

"""Y por último tenemos que crear un dataloader que nos permita:

-  Muestrear batches de muestras para pasárselos a la red durante el entrenamiento
-  Desordenar los datos
-  Cargar los datos en paralelo usando múltiples cores.

``torch.utils.data.DataLoader`` es un iterador que proporciona todas estas características. Un parámetro importante del iterador es ``collate_fn``. Podemos especificar cómo se organizan las muestras en batches eligiendo la función más adecuada. En cualquier caso, la opción por defecto debería funcionar bien en la mayoría de los casos.



"""

#Especificamos el dataset de train, un tamaño de batch de 8, desordenamos las imágenes, 
# y paralelizamos con 4 workers
train_dataloader = DataLoader(train_dataset, batch_size=8,
                        shuffle=True, num_workers=4)

#Dataset de validación => No desordenamos
#Como no hay que hacer backward, podemos aumentar mucho el batch_size
val_dataloader = DataLoader(val_dataset, batch_size=128,
                        shuffle=False, num_workers=4)

#Dataset de test => No desordenamos
test_dataloader = DataLoader(test_dataset, batch_size=128,
                        shuffle=False, num_workers=4)


# Función auxiliar para visualizar un batch de datos
def show_batch(sample_batched):
    """Mostramos las lesiones de un batch."""
    images_batch, labels_batch = \
            sample_batched['image'], sample_batched['label']
    batch_size = len(images_batch)
    im_size = images_batch.size(2)
    grid_border_size = 2
    
    #Generamos el grid
    grid = utils.make_grid(images_batch)
    #Lo pasamos a numpy y lo desnormalizamos
    grid=grid.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    grid = std * grid + mean
    grid = np.clip(grid, 0, 1)
    plt.imshow(grid)
    plt.title('Batch from dataloader')

for i_batch, sample_batched in enumerate(train_dataloader):
    

         #Mostramos datos de los 4 primeros batches y paramos.
    plt.axis('off')
    plt.ioff()
    plt.show()
    print(i_batch, sample_batched['image'].size(),
          sample_batched['label'])
    if i_batch == 3:
        plt.figure()
        show_batch(sample_batched)
        
        break

"""## Parte 2: Hacer fine-tuning de un modelo pre-entrenado

En la segunda parte de la práctica vamos a construir un sistema automático de diagnóstico de lesiones cutáneas. Para ello, en vez de entrenar una CNN diseñada por nosotros desde el principio, vamos a hacer un fine-tuning de una red que previamente ha sido entrenada para otra tarea. Como se ha visto en teoría, esta suele ser una buena alternativa cuando no se dispone de numerosos datos para entrenar (en proporción con los parámetros a aprender).

En particular, vamos a utilizar la red resnet-50, incluída en el paquete ``torchvision``.

### Métrica de evaluación de rendimiento
Comenzaremos definiendo la métrica que emplearemos para evaluar nuestra red. En particular, y siguiendo las instrucciones de los organizadores del challenge original ISIC, usaremos el área bajo la curva ROC o AUC, pero calcularemos 3 AUCs:
1) AUC del problema binario melanoma vs all
2) AUC del problema binario queratosis seborreica vs all
3) AUC promedio de las dos anteriores

La siguiente función permite calcular las AUCs a partir de las salidas completas de la base de datos:


"""

#Función que devuelve las AUCs de melanoma vs all y de queratosis vs all
# outputs es nx3: n el número de muestras en la base de datos
# labels es nx1
# La función devuelve un array de dos posiciones con los valores de las aucs
def computeAUCs(outputs,labels):
                
    aucs = np.zeros((2,))
    #Calculamos el AUC melanoma vs all
    scores_mel = outputs[:,1]
    labels_mel = (labels == 1).astype(np.int) 
    aucs[0]=metrics.roc_auc_score(labels_mel, scores_mel)

    #Calculamos el AUC queratosis vs all
    scores_sk = outputs[:,2]
    labels_sk = (labels == 2).astype(np.int) 
    aucs[1]=metrics.roc_auc_score(labels_sk, scores_sk)
    
    return aucs

"""### Función de entrenamiento

Continuamos definiendo la función que emplearemos para entrenar nuestro clasificador:
"""

#Los parámetros de train_model son la red (model), el criterio (la loss),
# el optimizador, una estrategia de lr, y las épocas de entrenamiento
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    since = time.time()
    
    numClasses = len(image_datasets['train'].classes)
    
    best_model_wts = copy.deepcopy(model.state_dict())
    best_aucs = np.zeros((2,)) #Usaremos el auc de melanoma vs all, queratosis vs all, y promedio 
    best_auc = 0
    #Bucle de épocas de entrenamiento
    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch, num_epochs - 1))
        print('-' * 10)

        
        
        # Cada época tiene entrenamiento y validación
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # Ponemos el modelo en modo entrenamiento
            else:
                model.eval()   # Ponemos el modelo en modo evaluación

            
            #Tamaño del dataset
            numSamples = dataset_sizes[phase]
            
            # Creamos las variables que almacenarán las salidas y las etiquetas
            outputs_m=np.zeros((numSamples,numClasses),dtype=np.float)
            labels_m=np.zeros((numSamples,),dtype=np.int)
            running_loss = 0.0
            
            contSamples=0
            
            # Iteramos sobre los datos.
            for sample in dataloaders[phase]:
                inputs = sample['image'].to(device).float()
                labels = sample['label'].to(device)
                
                
                #Tamaño del batch
                batchSize = labels.shape[0]
                
                # Ponemos a cero los gradientes
                optimizer.zero_grad()

                # Paso forward
                # registramos operaciones solo en train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    # backward y optimización solo en training
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()
                
                # Sacamos estadísticas y actualizamos variables
                running_loss += loss.item() * inputs.size(0)
                
                #Aplicamos un softmax a la salida
                outputs=F.softmax(outputs.data,dim=1)
                outputs_m [contSamples:contSamples+batchSize,...]=outputs.cpu().numpy()
                labels_m [contSamples:contSamples+batchSize]=labels.cpu().numpy()
                contSamples+=batchSize
                
            #Actualizamos la estrategia de lr    
            if phase == 'train':
                scheduler.step()
            
            #Loss acumulada en la época
            epoch_loss = running_loss / dataset_sizes[phase]
            
            #Calculamos las AUCs
            aucs=computeAUCs(outputs_m,labels_m)
            
            #Y la promedio
            epoch_auc = aucs.mean()
                         
            print('{} Loss: {:.4f} AUC mel: {:.4f} sk: {:.4f} avg: {:.4f}'.format(
                phase, epoch_loss, aucs[0], aucs[1], epoch_auc))

            # copia profunda del mejor modelo
            if phase == 'val' and epoch_auc > best_auc:
                best_auc = epoch_auc
                best_aucs = aucs.copy()        
                best_model_wts = copy.deepcopy(model.state_dict())

        print()

    time_elapsed = time.time() - since
    print('Training complete in {:.0f}m {:.0f}s'.format(
        time_elapsed // 60, time_elapsed % 60))
    print('Best val AUCs: mel {:4f} sk {:4f} avg {:4f}'.format(best_aucs[0],best_aucs[1],best_auc))

    # load best model weights
    model.load_state_dict(best_model_wts)
    return model

"""Ahora incluiremos una función auxiliar para visualizar algunas predicciones:"""

def visualize_model(model, num_images=6):
    was_training = model.training
    model.eval()
    images_so_far = 0
    fig = plt.figure()

    with torch.no_grad():
        for i, sample in enumerate(dataloaders['val']):
            inputs = sample['image'].to(device).float()
            labels = sample['label'].to(device)
            

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            for j in range(inputs.size()[0]):
                images_so_far += 1
                ax = plt.subplot(num_images//2, 2, images_so_far)
                ax.axis('off')
                ax.set_title('predicted: {}'.format(class_names[preds[j]]))
                imshow(inputs.cpu().data[j])

                if images_so_far == num_images:
                    model.train(mode=was_training)
                    return
        model.train(mode=was_training)

"""### Definimos el fine-tuning de una CNN
Una vez hemos definido las funciones de entrenamiento y evaluación, vamos a realizar el fine-tuning de resnet-50 sobre nuestra base de datos
"""

model_ft = models.resnet18(pretrained=True)
num_ftrs = model_ft.fc.in_features
# Tenemos que ajustar la capa de salida para que proporcione 3 scores (nevus, melanoma, y queratosis).
model_ft.fc = nn.Linear(num_ftrs, len(train_dataset.classes))

model_ft = model_ft.to(device)

criterion = nn.CrossEntropyLoss()

# Usaremos SGD con momento para optimizar
optimizer_ft = optim.SGD(model_ft.parameters(), lr=1.05e-3, momentum=0.9)

# Un factor lr que  decae 0.1 cada 7 épocas
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.01)

"""### Especificamos las lecturas de datos
Ahora vamos a asignar los dataloaders que teníamos anteriormente a los conjuntos de train y val
"""

image_datasets = {'train' : train_dataset, 'val': val_dataset}

dataloaders = {'train' : train_dataloader, 'val': val_dataloader}
          
dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}
class_names = image_datasets['train'].classes

"""### Entrenamos"""

##PROBAR CON 10 ÉPOCAS, QUE SOBREAJUSTA MENOS
model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,
                       num_epochs=10)

##GUARDA MODELOS 
##Para usarlo tienes que especificar en buffer el nombre con el que quieras guardarlo y la extensión .pth
buffer = 'model_01.pth'
torch.save(model_ft.state_dict(), buffer)

"""## Parte 3: Evaluación (Importante)
De esta práctica surge la primera evaluación de la asignatura. Para ello se pide a los alumnos lo siguiente:

- Traten de proponer y evaluar mejoras sobre la red baseline.
- En función de sus pruebas, seleccionen 2 posibles arquitecturas y, para cada una de ellas, generen una matriz de salidas para la base de datos de test. La matriz tendrá un tamaño 600x3, 600 lesiones y las 3 clases consideradas en el problema. La matriz deberá proporcionarse en formato csv (con 3 números por fila separados por ',').

La evaluación se hará a través de la competición, y cada grupo obtendrá el resultado asociado a la mejor de sus dos propuestas. 

Además, los alumnos entregarán un breve informe (1 cara para la descripción, 1 cara de referencias y figuras si fuese necesaria) donde describirán los aspectos más importantes de la solución propuesta. El objetivo de este informe es que el profesor valore los desarrollos/extensiones/decisiones tomadas por las alumnos a la hora de optimizar su sistema. No es necesario que se proporcione un nivel de detalle absoluto sobre los cambios realizados, simplemente enumerarlos y discutir brevemente el objetivo de los mismos. La nota final dependerá tanto del resultado del challenge como del informe.

IMPORTANTE: Se requiere que en el informe se indique claramente qué ha hecho cada uno de los miembros del grupo, de modo que se pueda valorar el trabajo individual. No se permite decir que todos han hecho todo, por lo que cada miembro del grupo se centrará en algunas mejoras/experimentos concretos.

La fecha límite de entrega del fichero de resultados y el informe es el miércoles 28 de Abril a las 23:59.

A continuación se proporcionan funciones para testear la red.
"""

### Código para generar la matriz de test
def test_model(model):
    since = time.time()
    
    numClasses = len(test_dataset.classes)
    
    model.eval()   # Ponemos el modelo en modo evaluación

    #Tamaño del dataset
    numSamples = len(test_dataset)
            
    # Creamos las variables que almacenarán las salidas y las etiquetas
    outputs_m=np.zeros((numSamples,numClasses),dtype=np.float)
    labels_m=np.zeros((numSamples,),dtype=np.int)
    contSamples=0
            
    # Iteramos sobre los datos.
    for sample in test_dataloader:
        inputs = sample['image'].to(device).float()
                
                
        #Tamaño del batch
        batchSize = inputs.shape[0]
                
        # Paso forward
        with torch.torch.no_grad():
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
                
            #Aplicamos un softmax a la salida
            outputs=F.softmax(outputs.data,dim=1)
            outputs_m [contSamples:contSamples+batchSize,...]=outputs.cpu().numpy()
            contSamples+=batchSize
                
            
    return outputs_m

"""Y ahora se propone el código para generar la matriz y el fichero CSV necesario"""

outputs=test_model(model_ft)

"""Y aquí el ejemplo para almacenar el fichero csv"""

import csv

with open('output_test.csv', mode='w') as out_file:
    csv_writer = csv.writer(out_file, delimiter=',')
    csv_writer.writerows(outputs);